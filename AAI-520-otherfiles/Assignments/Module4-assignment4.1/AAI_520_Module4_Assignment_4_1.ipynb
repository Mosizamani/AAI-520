{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "194f187a",
   "metadata": {},
   "source": [
    "# Assignment 4.1: \n",
    "Retrieval-Augmented Question Answering Using LangChain\n",
    "\n",
    "Student: Mostafa Zamaniturk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91edccf",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "In this assignment, you will explore how retrieval-augmented generation (RAG) improves language model responses by grounding them in real data. Using TED Talk transcripts, you'll combine semantic search with a transformer model to generate accurate, context-aware answers.\n",
    "\n",
    "The purpose of this assignment is to build a simple question answering (QA) system using Retrieval-augmented generation (RAG) techniques. You will use LangChain and HuggingFace tools to load a TED Talks dataset, embed and store document chunks using a vector database (FAISS), and query them using a pretrained transformer model. \n",
    "\n",
    "Through this assignment, students will gain hands-on experience in building real-world QA systems using open-domain documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279fa4ec",
   "metadata": {},
   "source": [
    "# Required Details\n",
    "Hint 1:\n",
    "\n",
    "Load a manageable subset of English translations from the TED Talks dataset, which is provided here for your convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6377793f",
   "metadata": {},
   "source": [
    "Hint 2:\n",
    "\n",
    "Some sample questions that you can ask:\n",
    "\n",
    "\"What do TED speakers say about climate change?\"\n",
    "\n",
    "\"What is the general opinion on education?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa9d41a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(2415) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from rank_bm25) (2.3.2)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "! pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "454d922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Required Libraries for LLM + Document Retrieval Workflow\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6896d205",
   "metadata": {},
   "source": [
    "The TED dataset had probem, so I decided to use wikipedia dataset as a reference for the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc861bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322511f35a9446d8a53ade082a0ae43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j_/2nhf1vq11vx6vp8923wmdmx40000gn/T/ipykernel_958/279505275.py:26: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load the document. \n",
    "dataset = load_dataset(\n",
    "    \"wikimedia/wikipedia\", \n",
    "    \"20231101.en\", \n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n",
    "documents = []\n",
    "for item in dataset:\n",
    "    text = item[\"text\"]\n",
    "    title = item.get(\"title\", \"Unknown\")\n",
    "    if text:\n",
    "        documents.append(\n",
    "            Document(\n",
    "                page_content=text,\n",
    "                metadata={\"title\": title, \"source\": \"wikipedia_20231101\"}\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split the document. Each chunk has 500 characters, and 100 characters overlap with the next chunk for context continuity.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents[:5])  # limit size to reduce memory\n",
    "\n",
    "# Step 4: Embed using Hugging Face sentence transformer\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a7e9dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcf0a05c30a4c6d9ee24b45b75e14ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea950dbb65ce44deae9ab6a3aa4e39a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e687581db44a61b5dd4e6e09fbf073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d5e4e50f7c47a2b3cfe4bf64e8646c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325b6eace5bf4d728a680d286f5dc5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4533d6629f748189338f3a68f056a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab55afafebf0492f8724f96d3832e67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question:  Explain the structure of DNA.\n",
      "\n",
      " Answer:\n",
      "DNA is a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonucleotide (ribonucleotide), a ribonu\n",
      "\n",
      " Source Documents:\n",
      "\n",
      "--- Source 1 ---\n",
      "Evolutionary\n",
      "\n",
      "--- Source 2 ---\n",
      "In English grammar, \"a\", and its variant \"an\", are indefinite articles.\n",
      "\n",
      "History \n",
      "\n",
      "The earliest known certain ancestor of \"A\" is aleph (also written 'aleph), the first letter of the Phoenician alphabet, which consisted entirely of consonants (for that reason, it is also called an abjad to distinguish it from a true alphabet). In turn, the ancestor of aleph may have been a pictogram of an ox head in proto-Sinaitic script influenced by Egyptian hieroglyphs, styled as a triangular head with two horns extended.\n",
      "\n",
      "--- Source 3 ---\n",
      "The Periplus of the Euxine Sea () gives the following details:\n",
      "\n",
      "--- Source 4 ---\n",
      "From 1826 to 1846, Tuscaloosa served as Alabama's capital. On January 30, 1846, the Alabama legislature announced it had voted to move the capital city from Tuscaloosa to Montgomery. The first legislative session in the new capital met in December 1847. A new capitol building was erected under the direction of Stephen Decatur Button of Philadelphia. The first structure burned down in 1849, but was rebuilt on the same site in 1851. This second capitol building in Montgomery remains to the present day. It was designed by Barachias Holt of Exeter, Maine.\n",
      "\n",
      "Civil War and Reconstruction\n",
      "\n",
      "--- Source 5 ---\n",
      "Two common optical albedos that are used in astronomy are the (V-band) geometric albedo (measuring brightness when illumination comes from directly behind the observer) and the Bond albedo (measuring total proportion of electromagnetic energy reflected). Their values can differ significantly, which is a common source of confusion.\n",
      "\n",
      "In detailed studies, the directional reflectance properties of astronomical bodies are often expressed in terms of the five Hapke parameters which semi-empirically describe the variation of albedo with phase angle, including a characterization of the opposition effect of regolith surfaces. One of these five parameters is yet another type of albedo called the single-scattering albedo. It is used to define scattering of electromagnetic waves on small particles. It depends on properties of the material (refractive index), the size of the particle, and the wavelength of the incoming radiation.\n",
      "\n",
      "--- Source 6 ---\n",
      "In the Spanish Civil War of 1936–39, anarchists and syndicalists (CNT and FAI) once again allied themselves with various currents of leftists. A long tradition of Spanish anarchism led to anarchists playing a pivotal role in the war, and particularly in the Spanish Revolution of 1936. In response to the army rebellion, an anarchist-inspired movement of peasants and workers, supported by armed militias, took control of Barcelona and of large areas of rural Spain, where they collectivised the land. The Soviet Union provided some limited assistance at the beginning of the war, but the result was a bitter fight between communists and other leftists in a series of events known as the May Days, as Joseph Stalin asserted Soviet control of the Republican government, ending in another defeat of anarchists at the hands of the communists.\n",
      "\n",
      "Post-WWII\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Load flan-t5-small on CPU (safest config). Hugging Face’s pipeline is wrapped into a LangChain-compatible llm\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "qa_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    max_length=256,\n",
    "    device=device,\n",
    "    do_sample=False\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=qa_pipeline)\n",
    "\n",
    "# Step 6: Build the Retrieval QA chain. First retrieves top 3 relevant text chunks from FAISS, then passes them to the LLM to answer your query.\n",
    "#It enhances the LLM's ability to answer questions by grounding it in specific documents.\n",
    "\n",
    "# retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Use hybrid search in LangChain FAISS and BM25\n",
    "# create a BM25 retriever\n",
    "\n",
    "# if it use text insted of document use this lines of codes\n",
    "    # bm25_retriever = BM25Retriever.from_texts([d.page_content for d in docs])\n",
    "    # bm25_retriever.k = 3\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = 3 # how many result to return\n",
    "\n",
    "# create a FAISS retriever\n",
    "faiss_retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# combine them with EnsemblerRetriever\n",
    "retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    "    weights=[0, 1] # balance BM25 and FAISS scores\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever, # hybrid retriever\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Step 7: Ask a question\n",
    "#query = \"What is tokenization in LLMs and why is it important?\"\n",
    "query = \"Explain the structure of DNA.\"\n",
    "result = qa_chain(query)\n",
    "\n",
    "# Step 8: Show results\n",
    "print(\"\\n Question: \", query)\n",
    "print(\"\\n Answer:\")\n",
    "print(result[\"result\"])\n",
    "\n",
    "print(\"\\n Source Documents:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"], 1):\n",
    "    print(f\"\\n--- Source {i} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db623267",
   "metadata": {},
   "source": [
    "- At first I used just faiss retriever, then I decided to improve the performance by using hybrid search in LangChain. For this purpose I implemented the BM25 to the model.\n",
    "- For the chunk size, I used 500 chunk size, and 100 for overlap. I recieved no meaning answers, then, I decided to change it to 1000 as chunk size and 200 for overlap, calculation time is significantly increased.\n",
    "- at first, I used the \"flan-t5-small\", answers were not correct (lahhucinated), then I used the \"flan-t5-base\" speed is decreased but answers were corect!\n",
    "- Other adjustments I need to try:\n",
    "    - different chunk size and overlap\n",
    "    - use other powerful models\n",
    "    - change the balance BM25 and FAISS, now is zero for BM25 and 100% for FAISS. \n",
    "    - for embeddings \"all-MiniLM-L6-v2\" is used, try to use different ones. if possible.\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665d26f",
   "metadata": {},
   "source": [
    "# Required Format\n",
    "Convert your Jupyter Notebook or Python script into a single, clean PDF or HTML document file. Be sure to label each section clearly and ensure that the outputs are properly visible in the document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
