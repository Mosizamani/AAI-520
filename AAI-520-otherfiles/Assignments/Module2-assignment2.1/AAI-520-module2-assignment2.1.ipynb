{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6480f24",
   "metadata": {},
   "source": [
    "Assignment 2.1: NLP, NER and PoS Tagging\n",
    "\n",
    "Mostafa Zamaniturk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae833262",
   "metadata": {},
   "source": [
    "Instructions\n",
    "In this assignment, you will apply Natural Language Processing (NLP), Named Entity Recognition (NER), and Part-of-Speech (PoS) techniques in NLP to analyze the Climate Fever dataset. The dataset contains climate change-related articles, and your task is to extract named entities and assign PoS tags to different parts of speech in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d7441",
   "metadata": {},
   "source": [
    "Instructions\n",
    "\n",
    "In this assignment, you will apply Natural Language Processing (NLP), Named Entity Recognition (NER), and Part-of-Speech (PoS) techniques in NLP to analyze the Climate Fever dataset. The dataset contains climate change-related articles, and your task is to extract named entities and assign PoS tags to different parts of speech in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ea7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7e2d8",
   "metadata": {},
   "source": [
    "Required Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357b9ae",
   "metadata": {},
   "source": [
    "1- Apply NER techniques to identify named entities (such as persons, organizations, locations, etc.) within the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44b85c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_label</th>\n",
       "      <th>evidences/0/evidence_id</th>\n",
       "      <th>evidences/0/evidence_label</th>\n",
       "      <th>evidences/0/article</th>\n",
       "      <th>evidences/0/evidence</th>\n",
       "      <th>evidences/0/entropy</th>\n",
       "      <th>evidences/0/votes/0</th>\n",
       "      <th>evidences/0/votes/1</th>\n",
       "      <th>...</th>\n",
       "      <th>evidences/4/evidence_id</th>\n",
       "      <th>evidences/4/evidence_label</th>\n",
       "      <th>evidences/4/article</th>\n",
       "      <th>evidences/4/evidence</th>\n",
       "      <th>evidences/4/entropy</th>\n",
       "      <th>evidences/4/votes/0</th>\n",
       "      <th>evidences/4/votes/1</th>\n",
       "      <th>evidences/4/votes/2</th>\n",
       "      <th>evidences/4/votes/3</th>\n",
       "      <th>evidences/4/votes/4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Global warming is driving polar bears toward e...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>Extinction risk from global warming:170</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>Extinction risk from global warming</td>\n",
       "      <td>\"Recent Research Shows Human Activity Driving ...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>...</td>\n",
       "      <td>Polar bear:1328</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>Polar bear</td>\n",
       "      <td>\"Bear hunting caught in global warming debate\".</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>The sun has gone into ‘lockdown’ which could c...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>Famine:386</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>Famine</td>\n",
       "      <td>The current consensus of the scientific commun...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter:5</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>Winter</td>\n",
       "      <td>In many regions, winter is associated with sno...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>The polar bear population has been growing.</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>Polar bear:1332</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>Polar bear</td>\n",
       "      <td>\"Ask the experts: Are polar bear populations i...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>...</td>\n",
       "      <td>Polar bear:61</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>Polar bear</td>\n",
       "      <td>Of the 19 recognized polar bear subpopulations...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Ironic' study finds more CO2 has slightly cool...</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>Atmosphere of Mars:131</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>Atmosphere of Mars</td>\n",
       "      <td>CO2 in the mesosphere acts as a cooling agent ...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>...</td>\n",
       "      <td>Carbon dioxide:191</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>Carbon dioxide</td>\n",
       "      <td>Less energy reaches the upper atmosphere, whic...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Human additions of CO2 are in the margin of er...</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>Carbon dioxide in Earth's atmosphere:140</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>Carbon dioxide in Earth's atmosphere</td>\n",
       "      <td>While CO 2 absorption and release is always ha...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>...</td>\n",
       "      <td>Sea:226</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>Sea</td>\n",
       "      <td>More recently, anthropogenic activities have s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim_id                                              claim claim_label  \\\n",
       "0         0  Global warming is driving polar bears toward e...    SUPPORTS   \n",
       "1         5  The sun has gone into ‘lockdown’ which could c...    SUPPORTS   \n",
       "2         6        The polar bear population has been growing.     REFUTES   \n",
       "3         9  Ironic' study finds more CO2 has slightly cool...     REFUTES   \n",
       "4        10  Human additions of CO2 are in the margin of er...     REFUTES   \n",
       "\n",
       "                    evidences/0/evidence_id evidences/0/evidence_label  \\\n",
       "0   Extinction risk from global warming:170            NOT_ENOUGH_INFO   \n",
       "1                                Famine:386                   SUPPORTS   \n",
       "2                           Polar bear:1332            NOT_ENOUGH_INFO   \n",
       "3                    Atmosphere of Mars:131            NOT_ENOUGH_INFO   \n",
       "4  Carbon dioxide in Earth's atmosphere:140            NOT_ENOUGH_INFO   \n",
       "\n",
       "                    evidences/0/article  \\\n",
       "0   Extinction risk from global warming   \n",
       "1                                Famine   \n",
       "2                            Polar bear   \n",
       "3                    Atmosphere of Mars   \n",
       "4  Carbon dioxide in Earth's atmosphere   \n",
       "\n",
       "                                evidences/0/evidence  evidences/0/entropy  \\\n",
       "0  \"Recent Research Shows Human Activity Driving ...             0.693147   \n",
       "1  The current consensus of the scientific commun...             0.000000   \n",
       "2  \"Ask the experts: Are polar bear populations i...             0.693147   \n",
       "3  CO2 in the mesosphere acts as a cooling agent ...             0.693147   \n",
       "4  While CO 2 absorption and release is always ha...             0.693147   \n",
       "\n",
       "  evidences/0/votes/0 evidences/0/votes/1  ... evidences/4/evidence_id  \\\n",
       "0            SUPPORTS     NOT_ENOUGH_INFO  ...         Polar bear:1328   \n",
       "1            SUPPORTS            SUPPORTS  ...                Winter:5   \n",
       "2     NOT_ENOUGH_INFO             REFUTES  ...           Polar bear:61   \n",
       "3     NOT_ENOUGH_INFO            SUPPORTS  ...      Carbon dioxide:191   \n",
       "4     NOT_ENOUGH_INFO             REFUTES  ...                 Sea:226   \n",
       "\n",
       "  evidences/4/evidence_label evidences/4/article  \\\n",
       "0            NOT_ENOUGH_INFO          Polar bear   \n",
       "1            NOT_ENOUGH_INFO              Winter   \n",
       "2                    REFUTES          Polar bear   \n",
       "3            NOT_ENOUGH_INFO      Carbon dioxide   \n",
       "4                    REFUTES                 Sea   \n",
       "\n",
       "                                evidences/4/evidence evidences/4/entropy  \\\n",
       "0    \"Bear hunting caught in global warming debate\".            0.693147   \n",
       "1  In many regions, winter is associated with sno...            0.693147   \n",
       "2  Of the 19 recognized polar bear subpopulations...            0.000000   \n",
       "3  Less energy reaches the upper atmosphere, whic...            0.000000   \n",
       "4  More recently, anthropogenic activities have s...            0.000000   \n",
       "\n",
       "  evidences/4/votes/0 evidences/4/votes/1  evidences/4/votes/2  \\\n",
       "0            SUPPORTS     NOT_ENOUGH_INFO                  NaN   \n",
       "1             REFUTES     NOT_ENOUGH_INFO                  NaN   \n",
       "2             REFUTES             REFUTES                  NaN   \n",
       "3     NOT_ENOUGH_INFO     NOT_ENOUGH_INFO                  NaN   \n",
       "4             REFUTES             REFUTES                  NaN   \n",
       "\n",
       "  evidences/4/votes/3 evidences/4/votes/4  \n",
       "0                 NaN                 NaN  \n",
       "1                 NaN                 NaN  \n",
       "2                 NaN                 NaN  \n",
       "3                 NaN                 NaN  \n",
       "4                 NaN                 NaN  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('climate-fever.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc86429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mostafazamaniturk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mostafazamaniturk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   claim_id                                              claim claim_label  \\\n",
      "0         0  Global warming is driving polar bears toward e...    SUPPORTS   \n",
      "1         5  The sun has gone into ‘lockdown’ which could c...    SUPPORTS   \n",
      "2         6        The polar bear population has been growing.     REFUTES   \n",
      "3         9  Ironic' study finds more CO2 has slightly cool...     REFUTES   \n",
      "4        10  Human additions of CO2 are in the margin of er...     REFUTES   \n",
      "\n",
      "                    evidences/0/evidence_id evidences/0/evidence_label  \\\n",
      "0   Extinction risk from global warming:170            NOT_ENOUGH_INFO   \n",
      "1                                Famine:386                   SUPPORTS   \n",
      "2                           Polar bear:1332            NOT_ENOUGH_INFO   \n",
      "3                    Atmosphere of Mars:131            NOT_ENOUGH_INFO   \n",
      "4  Carbon dioxide in Earth's atmosphere:140            NOT_ENOUGH_INFO   \n",
      "\n",
      "                    evidences/0/article  \\\n",
      "0   Extinction risk from global warming   \n",
      "1                                Famine   \n",
      "2                            Polar bear   \n",
      "3                    Atmosphere of Mars   \n",
      "4  Carbon dioxide in Earth's atmosphere   \n",
      "\n",
      "                                evidences/0/evidence  evidences/0/entropy  \\\n",
      "0  \"Recent Research Shows Human Activity Driving ...             0.693147   \n",
      "1  The current consensus of the scientific commun...             0.000000   \n",
      "2  \"Ask the experts: Are polar bear populations i...             0.693147   \n",
      "3  CO2 in the mesosphere acts as a cooling agent ...             0.693147   \n",
      "4  While CO 2 absorption and release is always ha...             0.693147   \n",
      "\n",
      "  evidences/0/votes/0 evidences/0/votes/1  ... evidences/3/votes/4_processed  \\\n",
      "0            SUPPORTS     NOT_ENOUGH_INFO  ...                            []   \n",
      "1            SUPPORTS            SUPPORTS  ...                            []   \n",
      "2     NOT_ENOUGH_INFO             REFUTES  ...                            []   \n",
      "3     NOT_ENOUGH_INFO            SUPPORTS  ...                            []   \n",
      "4     NOT_ENOUGH_INFO             REFUTES  ...                            []   \n",
      "\n",
      "  evidences/4/evidence_id_processed evidences/4/evidence_label_processed  \\\n",
      "0                           [polar]                                   []   \n",
      "1                                []                                   []   \n",
      "2                           [polar]                            [refutes]   \n",
      "3                          [carbon]                                   []   \n",
      "4                                []                            [refutes]   \n",
      "\n",
      "  evidences/4/article_processed  \\\n",
      "0                 [polar, bear]   \n",
      "1                      [winter]   \n",
      "2                 [polar, bear]   \n",
      "3             [carbon, dioxide]   \n",
      "4                         [sea]   \n",
      "\n",
      "                      evidences/4/evidence_processed  \\\n",
      "0   [bear, hunting, caught, global, warming, debate]   \n",
      "1  [many, regions, winter, associated, snow, free...   \n",
      "2  [recognized, polar, bear, subpopulations, one,...   \n",
      "3  [less, energy, reaches, upper, atmosphere, the...   \n",
      "4  [recently, anthropogenic, activities, steadily...   \n",
      "\n",
      "  evidences/4/votes/0_processed evidences/4/votes/1_processed  \\\n",
      "0                    [supports]                            []   \n",
      "1                     [refutes]                            []   \n",
      "2                     [refutes]                     [refutes]   \n",
      "3                            []                            []   \n",
      "4                     [refutes]                     [refutes]   \n",
      "\n",
      "   evidences/4/votes/2_processed evidences/4/votes/3_processed  \\\n",
      "0                             []                            []   \n",
      "1                             []                            []   \n",
      "2                             []                            []   \n",
      "3                             []                            []   \n",
      "4                             []                            []   \n",
      "\n",
      "  evidences/4/votes/4_processed  \n",
      "0                            []  \n",
      "1                            []  \n",
      "2                            []  \n",
      "3                            []  \n",
      "4                            []  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download resources (run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# define a function to do all tokenization, Lowercasing and removing stopwords:\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Handle missing or non-string values\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Lowercasing\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "\n",
    "    # Remove stopwords and keep only alphabetic words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    return filtered_tokens\n",
    "\n",
    "# Apply only to text (string/object) columns, keep originals intact\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[f\"{col}_processed\"] = df[col].apply(preprocess_text)\n",
    "\n",
    "# Show a preview\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca596b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts all columns in the pandas DataFrame df to the data type str (string)\n",
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935bbce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (0.17.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (2.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
      "Requirement already satisfied: wrapt in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from jinja2->spacy) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d47c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               claim  \\\n",
      "0  Global warming is driving polar bears toward e...   \n",
      "1  The sun has gone into ‘lockdown’ which could c...   \n",
      "2        The polar bear population has been growing.   \n",
      "3  Ironic' study finds more CO2 has slightly cool...   \n",
      "4  Human additions of CO2 are in the margin of er...   \n",
      "5  They tell us that we are the primary forces co...   \n",
      "6  The Great Barrier Reef is experiencing the mos...   \n",
      "7  it’s not a pollutant that threatens human civi...   \n",
      "8  If CO2 was so terrible for the planet, then in...   \n",
      "9  Sea level rise has been slow and a constant, p...   \n",
      "\n",
      "                                      claim_entities  \n",
      "0                                                 []  \n",
      "1                                                 []  \n",
      "2                                                 []  \n",
      "3                    [(Ironic, ORG), (CO2, PRODUCT)]  \n",
      "4  [(CO2, PRODUCT), (CO2, PRODUCT), (the last ice...  \n",
      "5                                                 []  \n",
      "6                                                 []  \n",
      "7                                                 []  \n",
      "8                    [(CO2, PERSON), (CO2, PRODUCT)]  \n",
      "9                                                 []  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define a function for NER\n",
    "def extract_entities(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "# List of columns you want to process\n",
    "text_columns = ['claim']  # replace with your text columns\n",
    "\n",
    "# Apply NER column by column\n",
    "for col in text_columns:\n",
    "    df[col + '_entities'] = df[col].astype(str).apply(extract_entities)\n",
    "\n",
    "# Show original columns and their corresponding _entities columns\n",
    "cols_to_show = text_columns + [col + '_entities' for col in text_columns]\n",
    "print(df[cols_to_show].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3e39f",
   "metadata": {},
   "source": [
    "2- Implement PoS tagging to assign appropriate parts of speech to different words in the text. \n",
    "\n",
    "Analyze the results and provide insights on the named entities and their corresponding parts of speech in the Climate Fever dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27281d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               claim  \\\n",
      "0  Global warming is driving polar bears toward e...   \n",
      "1  The sun has gone into ‘lockdown’ which could c...   \n",
      "2        The polar bear population has been growing.   \n",
      "3  Ironic' study finds more CO2 has slightly cool...   \n",
      "4  Human additions of CO2 are in the margin of er...   \n",
      "5  They tell us that we are the primary forces co...   \n",
      "6  The Great Barrier Reef is experiencing the mos...   \n",
      "7  it’s not a pollutant that threatens human civi...   \n",
      "8  If CO2 was so terrible for the planet, then in...   \n",
      "9  Sea level rise has been slow and a constant, p...   \n",
      "\n",
      "                                           claim_pos  \n",
      "0  [(Global, ADJ), (warming, NOUN), (is, AUX), (d...  \n",
      "1  [(The, DET), (sun, NOUN), (has, AUX), (gone, V...  \n",
      "2  [(The, DET), (polar, ADJ), (bear, NOUN), (popu...  \n",
      "3  [(Ironic, ADJ), (', PUNCT), (study, NOUN), (fi...  \n",
      "4  [(Human, ADJ), (additions, NOUN), (of, ADP), (...  \n",
      "5  [(They, PRON), (tell, VERB), (us, PRON), (that...  \n",
      "6  [(The, DET), (Great, PROPN), (Barrier, PROPN),...  \n",
      "7  [(it, PRON), (’s, VERB), (not, PART), (a, DET)...  \n",
      "8  [(If, SCONJ), (CO2, NOUN), (was, AUX), (so, AD...  \n",
      "9  [(Sea, NOUN), (level, NOUN), (rise, NOUN), (ha...  \n"
     ]
    }
   ],
   "source": [
    "# Define a function for POS tagging\n",
    "def extract_pos(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    doc = nlp(text)\n",
    "    # Return a list of tuples (word, POS tag)\n",
    "    return [(token.text, token.pos_) for token in doc]\n",
    "\n",
    "# List of columns you want to process\n",
    "text_columns = ['claim']  # replace with your text columns\n",
    "\n",
    "# Apply POS tagging column by column\n",
    "for col in text_columns:\n",
    "    df[col + '_pos'] = df[col].astype(str).apply(extract_pos)\n",
    "\n",
    "# Show original columns and their corresponding _pos columns\n",
    "cols_to_show = text_columns + [col + '_pos' for col in text_columns]\n",
    "print(df[cols_to_show].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc715941",
   "metadata": {},
   "source": [
    "3- Visualize the findings using appropriate graphs, charts, or tables to enhance understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49975a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (9.5.0)\n",
      "Requirement already satisfied: decorator in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from ipython) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from ipython) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from jedi>=0.16->ipython) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from stack_data->ipython) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages (from stack_data->ipython) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd5322a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (/Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages/IPython/core/display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n\u001b[32m      2\u001b[39m display(HTML(\u001b[33m\"\u001b[39m\u001b[33m<b>Hello</b>\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'display' from 'IPython.core.display' (/Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages/IPython/core/display.py)"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<b>Hello</b>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aed8210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages/spacy/displacy/__init__.py:213: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (/Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages/IPython/core/display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m doc = nlp(sample_text)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Visualize Named Entities\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mdisplacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ment\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjupyter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/py313/lib/python3.13/site-packages/spacy/displacy/__init__.py:69\u001b[39m, in \u001b[36mrender\u001b[39m\u001b[34m(docs, style, page, minify, jupyter, options, manual)\u001b[39m\n\u001b[32m     65\u001b[39m     html = RENDER_WRAPPER(html)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jupyter \u001b[38;5;129;01mor\u001b[39;00m (jupyter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_in_jupyter()):\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# return HTML rendered by IPython display()\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# See #4840 for details on span wrapper to disable mathjax\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTML, display\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m display(HTML(\u001b[33m'\u001b[39m\u001b[33m<span class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtex2jax_ignore\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m</span>\u001b[39m\u001b[33m'\u001b[39m.format(html)))\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m html\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'display' from 'IPython.core.display' (/Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages/IPython/core/display.py)"
     ]
    }
   ],
   "source": [
    "# --- Visualization using displacy for a single example ---\n",
    "# Choose a row to visualize (e.g., the first row)\n",
    "sample_text = df.loc[0, 'claim']\n",
    "doc = nlp(sample_text)\n",
    "\n",
    "# Visualize Named Entities\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ffe15fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (/Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages/IPython/core/display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m doc = nlp(sample_text)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Visualize POS tags and dependencies\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mdisplacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdep\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjupyter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/py313/lib/python3.13/site-packages/spacy/displacy/__init__.py:69\u001b[39m, in \u001b[36mrender\u001b[39m\u001b[34m(docs, style, page, minify, jupyter, options, manual)\u001b[39m\n\u001b[32m     65\u001b[39m     html = RENDER_WRAPPER(html)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jupyter \u001b[38;5;129;01mor\u001b[39;00m (jupyter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_in_jupyter()):\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# return HTML rendered by IPython display()\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# See #4840 for details on span wrapper to disable mathjax\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTML, display\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m display(HTML(\u001b[33m'\u001b[39m\u001b[33m<span class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtex2jax_ignore\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m</span>\u001b[39m\u001b[33m'\u001b[39m.format(html)))\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m html\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'display' from 'IPython.core.display' (/Users/mostafazamaniturk/.venvs/py313/lib/python3.13/site-packages/IPython/core/display.py)"
     ]
    }
   ],
   "source": [
    "# --- Visualization using displacy for POS tags ---\n",
    "# Choose a row to visualize (e.g., the first row)\n",
    "sample_text = df.loc[0, 'claim']\n",
    "doc = nlp(sample_text)\n",
    "\n",
    "# Visualize POS tags and dependencies\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42982c29",
   "metadata": {},
   "source": [
    "4- Summarize your approach, the findings, and any challenges faced during the process.\n",
    "\n",
    "Note: You are free to use any additional techniques or libraries to enhance the NER and PoS tagging tasks. Make sure to provide proper documentation and references for any external resources used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a366a16",
   "metadata": {},
   "source": [
    "Challenges:\n",
    "- displacy does not work in my Jupiter file\n",
    "- if I have a big dataset, should I write code for each column separately? Because at first i wrote my code for all columns but it takes long long time.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266f452",
   "metadata": {},
   "source": [
    "Required Format\n",
    "\n",
    "To prepare for assignment submission, convert your Jupyter Notebook to a single, clean PDF or HTML document file. Your deliverable should contain your implementations of the tasks above, as well as any additional comments or observations you may have. Please ensure the PDF or MS Word document displays the code and output appropriately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
